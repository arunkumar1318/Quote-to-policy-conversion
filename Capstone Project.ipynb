{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdd015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandasql as psql\n",
    "# pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c15c46c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Num</th>\n",
       "      <th>Agent_Type</th>\n",
       "      <th>Q_Creation_DT</th>\n",
       "      <th>Q_Valid_DT</th>\n",
       "      <th>Policy_Bind_DT</th>\n",
       "      <th>Region</th>\n",
       "      <th>Agent_Num</th>\n",
       "      <th>Policy_Type</th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Range1</th>\n",
       "      <th>Sal_Range2</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Veh_Usage</th>\n",
       "      <th>Annual_Miles_Range</th>\n",
       "      <th>Vehicl_Cost_Range1</th>\n",
       "      <th>Vehicl_Cost_Range2</th>\n",
       "      <th>Re_Quote</th>\n",
       "      <th>Quoted_Premium</th>\n",
       "      <th>Policy_Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQ-C-139212</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/04/25</td>\n",
       "      <td>2020/06/23</td>\n",
       "      <td>2020/05/23</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>Car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 25 K &lt;= $ 40 K</td>\n",
       "      <td>&gt;  25 K &lt;=  40 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 55 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>693.86</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQ-F-136117</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2020/04/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2153</td>\n",
       "      <td>Van</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 7.5 K &amp; &lt;= 15 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>635.96</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ-F-126801</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/06/19</td>\n",
       "      <td>2020/08/17</td>\n",
       "      <td>2020/07/12</td>\n",
       "      <td>F</td>\n",
       "      <td>2056</td>\n",
       "      <td>Truck</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>780.64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQ-E-143467</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/05/02</td>\n",
       "      <td>2020/06/30</td>\n",
       "      <td>2020/05/24</td>\n",
       "      <td>E</td>\n",
       "      <td>2138</td>\n",
       "      <td>Car</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 90 K</td>\n",
       "      <td>&gt;  90 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&lt;= 7.5 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>723.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQ-C-143827</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/12</td>\n",
       "      <td>2020/04/11</td>\n",
       "      <td>2020/02/25</td>\n",
       "      <td>C</td>\n",
       "      <td>2327</td>\n",
       "      <td>Truck</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $ 25 K</td>\n",
       "      <td>&lt;=  25 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>738.14</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quote_Num Agent_Type Q_Creation_DT  Q_Valid_DT Policy_Bind_DT Region  \\\n",
       "0  AQ-C-139212         EA    2020/04/25  2020/06/23     2020/05/23      C   \n",
       "1  AQ-F-136117         EA    2020/02/21  2020/04/20            NaN      F   \n",
       "2  AQ-F-126801         EA    2020/06/19  2020/08/17     2020/07/12      F   \n",
       "3  AQ-E-143467         EA    2020/05/02  2020/06/30     2020/05/24      E   \n",
       "4  AQ-C-143827         EA    2020/02/12  2020/04/11     2020/02/25      C   \n",
       "\n",
       "   Agent_Num Policy_Type  HH_Vehicles  HH_Drivers  ...          Sal_Range1  \\\n",
       "0       2156         Car            3           3  ...  > $ 25 K <= $ 40 K   \n",
       "1       2153         Van            2           2  ...  > $ 40 K <= $ 60 K   \n",
       "2       2056       Truck            2           1  ...  > $ 40 K <= $ 60 K   \n",
       "3       2138         Car            1           2  ...           > $ 90 K    \n",
       "4       2327       Truck            3           1  ...           <= $ 25 K   \n",
       "\n",
       "         Sal_Range2  Coverage  Veh_Usage Annual_Miles_Range  \\\n",
       "0  >  25 K <=  40 K  Balanced    Commute             > 55 K   \n",
       "1  >  40 K <=  60 K  Balanced   Pleasure  > 7.5 K & <= 15 K   \n",
       "2  >  40 K <=  60 K     Basic    Commute   > 35 K & <= 45 K   \n",
       "3          >  90 K      Basic   Pleasure           <= 7.5 K   \n",
       "4          <=  25 K     Basic   Pleasure   > 35 K & <= 45 K   \n",
       "\n",
       "   Vehicl_Cost_Range1 Vehicl_Cost_Range2 Re_Quote Quoted_Premium Policy_Bind  \n",
       "0  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         693.86         Yes  \n",
       "1           <= $ 10 K           <=  10 K       No         635.96          No  \n",
       "2  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         780.64         Yes  \n",
       "3           <= $ 10 K           <=  10 K       No         723.15         Yes  \n",
       "4           <= $ 10 K           <=  10 K       No         738.14         Yes  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Auto Quote Ins data\n",
    "AutoIns = pd.read_csv(r\"C:\\Users\\ARUN KUMAR\\Desktop\\capstone_Project_1\\Auto_Quote_Data_V2.0.csv\", header=0)\n",
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25bf667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Num</th>\n",
       "      <th>Agent_Type</th>\n",
       "      <th>Q_Creation_DT</th>\n",
       "      <th>Q_Valid_DT</th>\n",
       "      <th>Policy_Bind_DT</th>\n",
       "      <th>Region</th>\n",
       "      <th>Agent_Num</th>\n",
       "      <th>Policy_Type</th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Range1</th>\n",
       "      <th>Sal_Range2</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Veh_Usage</th>\n",
       "      <th>Annual_Miles_Range</th>\n",
       "      <th>Vehicl_Cost_Range1</th>\n",
       "      <th>Vehicl_Cost_Range2</th>\n",
       "      <th>Re_Quote</th>\n",
       "      <th>Quoted_Premium</th>\n",
       "      <th>Policy_Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Quote_Num, Agent_Type, Q_Creation_DT, Q_Valid_DT, Policy_Bind_DT, Region, Agent_Num, Policy_Type, HH_Vehicles, HH_Drivers, Driver_Age, Driving_Exp, Prev_Accidents, Prev_Citations, Gender, Marital_Status, Education, Sal_Range1, Sal_Range2, Coverage, Veh_Usage, Annual_Miles_Range, Vehicl_Cost_Range1, Vehicl_Cost_Range2, Re_Quote, Quoted_Premium, Policy_Bind]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying Duplicate values with in dataset\n",
    "AutoIns_dup = AutoIns[AutoIns.duplicated(keep='last')]\n",
    "AutoIns_dup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e105cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable data type into interger\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('Yes', '1')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('No', '0')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23652ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 113757\n",
      "Class 1: 32502\n",
      "Proportion: 3.5 : 1\n",
      "Total Records: 146259\n"
     ]
    }
   ],
   "source": [
    "# Count the target or dependent variable by '0' & '1' and\n",
    "# their proportion (> 10 : 1, then the dataset is imbalance dataset)\n",
    "Policy_Bind_count = AutoIns.Policy_Bind.value_counts()\n",
    "print('Class 0:', Policy_Bind_count[0])\n",
    "print('Class 1:', Policy_Bind_count[1])\n",
    "print('Proportion:', round(Policy_Bind_count[0] / Policy_Bind_count[1], 2), ': 1')\n",
    "print('Total Records:', len(AutoIns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67c7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and new column as 'QP_Range' from 'Quoted_premium'\n",
    "AutoIns['QP_Range'] = pd.cut(AutoIns['Quoted_Premium'], [0, 800, 1000, 1200, 9999],\n",
    " labels=['0-800', '801-1000', '1001-1200', '>1200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5b9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables which are impacting the target variable\n",
    "AutoIns = AutoIns.drop(['Quote_Num', 'Agent_Num', 'Q_Creation_DT', 'Q_Valid_DT', 'Policy_Bind_DT',\n",
    " 'Sal_Range1', 'Vehicl_Cost_Range1', 'Quoted_Premium'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f906ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146259 entries, 0 to 146258\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   Agent_Type          146259 non-null  object  \n",
      " 1   Region              146259 non-null  object  \n",
      " 2   Policy_Type         146259 non-null  object  \n",
      " 3   HH_Vehicles         146259 non-null  int64   \n",
      " 4   HH_Drivers          146259 non-null  int64   \n",
      " 5   Driver_Age          146259 non-null  int64   \n",
      " 6   Driving_Exp         146259 non-null  int64   \n",
      " 7   Prev_Accidents      146259 non-null  int64   \n",
      " 8   Prev_Citations      146259 non-null  int64   \n",
      " 9   Gender              146259 non-null  object  \n",
      " 10  Marital_Status      146259 non-null  object  \n",
      " 11  Education           146259 non-null  object  \n",
      " 12  Sal_Range2          146259 non-null  object  \n",
      " 13  Coverage            146259 non-null  object  \n",
      " 14  Veh_Usage           146259 non-null  object  \n",
      " 15  Annual_Miles_Range  146259 non-null  object  \n",
      " 16  Vehicl_Cost_Range2  146259 non-null  object  \n",
      " 17  Re_Quote            146259 non-null  object  \n",
      " 18  Policy_Bind         146259 non-null  int32   \n",
      " 19  QP_Range            146259 non-null  category\n",
      "dtypes: category(1), int32(1), int64(6), object(12)\n",
      "memory usage: 20.8+ MB\n"
     ]
    }
   ],
   "source": [
    "AutoIns.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9b4111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agent_Type', 'Region', 'Policy_Type', 'HH_Vehicles', 'HH_Drivers',\n",
       "       'Driver_Age', 'Driving_Exp', 'Prev_Accidents', 'Prev_Citations',\n",
       "       'Gender', 'Marital_Status', 'Education', 'Sal_Range2', 'Coverage',\n",
       "       'Veh_Usage', 'Annual_Miles_Range', 'Vehicl_Cost_Range2', 'Re_Quote',\n",
       "       'Policy_Bind', 'QP_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the columns of data\n",
    "AutoIns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718c7da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>Driver_Age</th>\n",
       "      <th>Driving_Exp</th>\n",
       "      <th>Prev_Accidents</th>\n",
       "      <th>Prev_Citations</th>\n",
       "      <th>Policy_Bind</th>\n",
       "      <th>Agent_Type_EA</th>\n",
       "      <th>Agent_Type_IA</th>\n",
       "      <th>Region_A</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  10 K &lt;=  20 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  20 K &lt;=  30 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  30 K &lt;=  40 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  40 K</th>\n",
       "      <th>Re_Quote_No</th>\n",
       "      <th>Re_Quote_Yes</th>\n",
       "      <th>QP_Range_0-800</th>\n",
       "      <th>QP_Range_801-1000</th>\n",
       "      <th>QP_Range_1001-1200</th>\n",
       "      <th>QP_Range_&gt;1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HH_Vehicles  HH_Drivers  Driver_Age  Driving_Exp  Prev_Accidents  \\\n",
       "0            3           3          43           26               0   \n",
       "1            2           2          30           13               0   \n",
       "2            2           1          25            8               0   \n",
       "3            1           2          43           26               0   \n",
       "4            3           1          40           23               0   \n",
       "\n",
       "   Prev_Citations  Policy_Bind  Agent_Type_EA  Agent_Type_IA  Region_A  ...  \\\n",
       "0               0            1              1              0         0  ...   \n",
       "1               0            0              1              0         0  ...   \n",
       "2               0            1              1              0         0  ...   \n",
       "3               0            1              1              0         0  ...   \n",
       "4               0            1              1              0         0  ...   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  10 K <=  20 K  Vehicl_Cost_Range2_>  20 K <=  30 K  \\\n",
       "0                                    1                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    1                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  30 K <=  40 K  Vehicl_Cost_Range2_>  40 K   \\\n",
       "0                                    0                            0   \n",
       "1                                    0                            0   \n",
       "2                                    0                            0   \n",
       "3                                    0                            0   \n",
       "4                                    0                            0   \n",
       "\n",
       "   Re_Quote_No  Re_Quote_Yes  QP_Range_0-800  QP_Range_801-1000  \\\n",
       "0            1             0               1                  0   \n",
       "1            1             0               1                  0   \n",
       "2            1             0               1                  0   \n",
       "3            1             0               1                  0   \n",
       "4            1             0               1                  0   \n",
       "\n",
       "   QP_Range_1001-1200  QP_Range_>1200  \n",
       "0                   0               0  \n",
       "1                   0               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoIns = pd.get_dummies(AutoIns, columns=['Agent_Type', 'Region', 'Policy_Type', 'Gender',\n",
    " 'Marital_Status', 'Education', 'Sal_Range2',\n",
    " 'Coverage', 'Veh_Usage', 'Annual_Miles_Range',\n",
    " 'Vehicl_Cost_Range2', 'Re_Quote', 'QP_Range'])\n",
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36911aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146259 entries, 0 to 146258\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                Non-Null Count   Dtype\n",
      "---  ------                                --------------   -----\n",
      " 0   HH_Vehicles                           146259 non-null  int64\n",
      " 1   HH_Drivers                            146259 non-null  int64\n",
      " 2   Driver_Age                            146259 non-null  int64\n",
      " 3   Driving_Exp                           146259 non-null  int64\n",
      " 4   Prev_Accidents                        146259 non-null  int64\n",
      " 5   Prev_Citations                        146259 non-null  int64\n",
      " 6   Policy_Bind                           146259 non-null  int32\n",
      " 7   Agent_Type_EA                         146259 non-null  uint8\n",
      " 8   Agent_Type_IA                         146259 non-null  uint8\n",
      " 9   Region_A                              146259 non-null  uint8\n",
      " 10  Region_B                              146259 non-null  uint8\n",
      " 11  Region_C                              146259 non-null  uint8\n",
      " 12  Region_D                              146259 non-null  uint8\n",
      " 13  Region_E                              146259 non-null  uint8\n",
      " 14  Region_F                              146259 non-null  uint8\n",
      " 15  Region_G                              146259 non-null  uint8\n",
      " 16  Region_H                              146259 non-null  uint8\n",
      " 17  Policy_Type_Car                       146259 non-null  uint8\n",
      " 18  Policy_Type_Truck                     146259 non-null  uint8\n",
      " 19  Policy_Type_Van                       146259 non-null  uint8\n",
      " 20  Gender_Female                         146259 non-null  uint8\n",
      " 21  Gender_Male                           146259 non-null  uint8\n",
      " 22  Marital_Status_Dirvorced              146259 non-null  uint8\n",
      " 23  Marital_Status_Married                146259 non-null  uint8\n",
      " 24  Marital_Status_Single                 146259 non-null  uint8\n",
      " 25  Marital_Status_Widow                  146259 non-null  uint8\n",
      " 26  Education_Bachelors                   146259 non-null  uint8\n",
      " 27  Education_College                     146259 non-null  uint8\n",
      " 28  Education_High School                 146259 non-null  uint8\n",
      " 29  Education_Masters                     146259 non-null  uint8\n",
      " 30  Education_Ph.D                        146259 non-null  uint8\n",
      " 31  Sal_Range2_<=  25 K                   146259 non-null  uint8\n",
      " 32  Sal_Range2_>  25 K <=  40 K           146259 non-null  uint8\n",
      " 33  Sal_Range2_>  40 K <=  60 K           146259 non-null  uint8\n",
      " 34  Sal_Range2_>  60 K <=  90 K           146259 non-null  uint8\n",
      " 35  Sal_Range2_>  90 K                    146259 non-null  uint8\n",
      " 36  Coverage_Balanced                     146259 non-null  uint8\n",
      " 37  Coverage_Basic                        146259 non-null  uint8\n",
      " 38  Coverage_Enhanced                     146259 non-null  uint8\n",
      " 39  Veh_Usage_Business                    146259 non-null  uint8\n",
      " 40  Veh_Usage_Commute                     146259 non-null  uint8\n",
      " 41  Veh_Usage_Pleasure                    146259 non-null  uint8\n",
      " 42  Annual_Miles_Range_<= 7.5 K           146259 non-null  uint8\n",
      " 43  Annual_Miles_Range_> 15 K & <= 25 K   146259 non-null  uint8\n",
      " 44  Annual_Miles_Range_> 25 K & <= 35 K   146259 non-null  uint8\n",
      " 45  Annual_Miles_Range_> 35 K & <= 45 K   146259 non-null  uint8\n",
      " 46  Annual_Miles_Range_> 45 K & <= 55 K   146259 non-null  uint8\n",
      " 47  Annual_Miles_Range_> 55 K             146259 non-null  uint8\n",
      " 48  Annual_Miles_Range_> 7.5 K & <= 15 K  146259 non-null  uint8\n",
      " 49  Vehicl_Cost_Range2_<=  10 K           146259 non-null  uint8\n",
      " 50  Vehicl_Cost_Range2_>  10 K <=  20 K   146259 non-null  uint8\n",
      " 51  Vehicl_Cost_Range2_>  20 K <=  30 K   146259 non-null  uint8\n",
      " 52  Vehicl_Cost_Range2_>  30 K <=  40 K   146259 non-null  uint8\n",
      " 53  Vehicl_Cost_Range2_>  40 K            146259 non-null  uint8\n",
      " 54  Re_Quote_No                           146259 non-null  uint8\n",
      " 55  Re_Quote_Yes                          146259 non-null  uint8\n",
      " 56  QP_Range_0-800                        146259 non-null  uint8\n",
      " 57  QP_Range_801-1000                     146259 non-null  uint8\n",
      " 58  QP_Range_1001-1200                    146259 non-null  uint8\n",
      " 59  QP_Range_>1200                        146259 non-null  uint8\n",
      "dtypes: int32(1), int64(6), uint8(53)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "AutoIns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb38a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "IndepVar = []\n",
    "for col in AutoIns.columns:\n",
    "    if col != 'Policy_Bind':\n",
    "        IndepVar.append(col)\n",
    "TargetVar = 'Policy_Bind'\n",
    "x = AutoIns[IndepVar]\n",
    "y = AutoIns[TargetVar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0719c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state =43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b562ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x, y, test_size = 0.30, stratify=y,  random_state =43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57e28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train['Driver_Age'] = sc.fit_transform(x_train['Driver_Age'].values.reshape(-1, 1))\n",
    "x_train['Driving_Exp'] = sc.fit_transform(x_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "x_test['Driver_Age'] = sc.fit_transform(x_test['Driver_Age'].values.reshape(-1, 1))\n",
    "x_test['Driving_Exp'] = sc.fit_transform(x_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "# Convert to dataframe\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a3099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x1_train['Driver_Age'] = sc.fit_transform(x1_train['Driver_Age'].values.reshape(-1, 1))\n",
    "x1_train['Driving_Exp'] = sc.fit_transform(x1_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "x1_test['Driver_Age'] = sc.fit_transform(x1_test['Driver_Age'].values.reshape(-1, 1))\n",
    "x1_test['Driving_Exp'] = sc.fit_transform(x1_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "# Convert to dataframe\n",
    "x1_train = pd.DataFrame(x1_train)\n",
    "x1_test = pd.DataFrame(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053c2a4",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44e747",
   "metadata": {},
   "source": [
    "# Decision Tree with Random Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49621c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the decision tree model with random sampling \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "AutoInsDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, \n",
    "                                   max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                   min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                                   min_weight_fraction_leaf=0.0, random_state=None, splitter='best') \n",
    "AutoInsDT = AutoInsDT.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d58652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set \n",
    "\n",
    "y_pred = AutoInsDT.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77e3764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25378  8731]\n",
      " [ 7309  2460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76     34109\n",
      "           1       0.22      0.25      0.23      9769\n",
      "\n",
      "    accuracy                           0.63     43878\n",
      "   macro avg       0.50      0.50      0.50     43878\n",
      "weighted avg       0.65      0.63      0.64     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5dcdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.44 %\n",
      "Precision: 21.98 %\n",
      "Recall: 25.18 %\n",
      "f1-score: 23.47 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "# Model Accuracy: how often is the classifier correct? \n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such? \n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred) * 100, 2)), '%') \n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such? \n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall \n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred) * 100, 2)), '%') \n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095fe8d",
   "metadata": {},
   "source": [
    "# Decision Tree with Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8fa1817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227514, 59)\n",
      "(227514,)\n"
     ]
    }
   ],
   "source": [
    "# Random oversampling can be implemented using the RandomOverSampler class\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over = RandomOverSampler(sampling_strategy='minority')\n",
    "x_over, y_over = over.fit_resample(x, y)\n",
    "\n",
    "print(x_over.shape)\n",
    "print(y_over.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63b85680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227514, 59)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7aac745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113757\n",
       "1    113757\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know the count of major and minor classes\n",
    "\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91b37e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xo_train, xo_test, yo_train, yo_test = train_test_split(x_over, y_over, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a35076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#x_train = sc.fit_transform(x_train)\n",
    "#x_test = sc.fit_transform(x_test)\n",
    "\n",
    "xo_train['Driver_Age'] = sc.fit_transform(xo_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_train['Driving_Exp'] = sc.fit_transform(xo_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xo_test['Driver_Age'] = sc.fit_transform(xo_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_test['Driving_Exp'] = sc.fit_transform(xo_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xo_train = pd.DataFrame(xo_train)\n",
    "xo_test = pd.DataFrame(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52c5738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under Sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_O = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                      max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                      min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                      random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_O = AutoInsDT_O.fit(xo_train, yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da361a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yo_pred = AutoInsDT_O.predict(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "392aefc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24282  9795]\n",
      " [ 2107 32071]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80     34077\n",
      "           1       0.77      0.94      0.84     34178\n",
      "\n",
      "    accuracy                           0.83     68255\n",
      "   macro avg       0.84      0.83      0.82     68255\n",
      "weighted avg       0.84      0.83      0.82     68255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report \n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6731298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.49 %\n",
      "Precision: 76.37 %\n",
      "Recall: 94.17 %\n",
      "f1-score: 84.34 %\n",
      "roc_auc_score: 0.825\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80add2",
   "metadata": {},
   "source": [
    "# Decision Tree with Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb2e7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the decision tree model with random sampling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "AutoInsDT_S = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    " max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    " min_impurity_decrease=0.0, min_impurity_split=None,\n",
    " min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    " random_state=None, splitter='best')\n",
    "AutoInsDT_S = AutoInsDT_S.fit(x1_train,y1_train)\n",
    "AutoInsDT_S = AutoInsDT_S.fit(x1_train,y1_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18222972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "y1_pred = AutoInsDT_S.predict(x1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a140431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25377  8750]\n",
      " [ 7298  2453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76     34127\n",
      "           1       0.22      0.25      0.23      9751\n",
      "\n",
      "    accuracy                           0.63     43878\n",
      "   macro avg       0.50      0.50      0.50     43878\n",
      "weighted avg       0.65      0.63      0.64     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4ee1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.43 %\n",
      "Precision: 21.9 %\n",
      "Recall: 25.16 %\n",
      "f1-score: 23.41 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y1_test, y1_pred) * 100, 2)), \"%\")\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y1_test, y1_pred) * 100, 2)), '%')\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y1_test, y1_pred) * 100, 2)), \"%\")\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y1_test, y1_pred) * 100, 2)), '%')\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y1_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404220db",
   "metadata": {},
   "source": [
    "# Decision Tree with Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03fe9ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65004, 59)\n",
      "(65004,)\n"
     ]
    }
   ],
   "source": [
    "# Random undersampling to balance the class distribution \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "x_under, y_under = under.fit_resample(x, y)\n",
    "\n",
    "print(x_under.shape)\n",
    "print(y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48fe035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32502\n",
       "1    32502\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba41d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xu_train, xu_test, yu_train, yu_test = train_test_split(x_under, y_under, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a12e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xu_train['Driver_Age'] = sc.fit_transform(xu_train['Driver_Age'].values.reshape(-1,1))\n",
    "xu_train['Driving_Exp'] = sc.fit_transform(xu_train['Driving_Exp'].values.reshape(-1,1))\n",
    "xu_train['Driver_Age'] = sc.fit_transform(xu_train['Driver_Age'].values.reshape(-1,1))\n",
    "xu_train['Driving_Exp'] = sc.fit_transform(xu_train['Driving_Exp'].values.reshape(-1,1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xu_train =  pd.DataFrame(xu_train)\n",
    "xu_test = pd.DataFrame(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2804abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_C = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "                                     min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                     random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                     min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "AutoInsDT_C = AutoInsDT_C.fit(xu_train, yu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6742ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yu_pred = AutoInsDT_C.predict(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b08c8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4924 4829]\n",
      " [4880 4869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50      9753\n",
      "           1       0.50      0.50      0.50      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classification report \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b7c2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.09 %\n",
      "Precision: 50.08 %\n",
      "Recall: 53.75 %\n",
      "f1-score: 51.85 %\n",
      "roc_auc_score: 0.501\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a689ba8",
   "metadata": {},
   "source": [
    "# Decision Tree - Combining Over Sampling and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad70e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159259, 59)\n",
      "(159259,)\n",
      "(159257, 59)\n",
      "(159257,)\n"
     ]
    }
   ],
   "source": [
    "# Combining Random Oversampling and Undersampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy=0.40)\n",
    "# fit and apply the transform\n",
    "x2, y2 = over.fit_resample(x, y)\n",
    "print(x2.shape)\n",
    "print(y2.shape)\n",
    "# define undersampling strategy\n",
    "under = RandomUnderSampler(sampling_strategy=0.40)\n",
    "# fit and apply the transform\n",
    "x3, y3 = under.fit_resample(x2, y2)\n",
    "print(x3.shape)\n",
    "print(y3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9545f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113755\n",
       "1     45502\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9d0a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xc_train, xc_test, yc_train, yc_test = train_test_split(x3, y3, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0f42ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xc_train['Driver_Age'] = sc.fit_transform(xc_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_train['Driving_Exp'] = sc.fit_transform(xc_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xc_test['Driver_Age'] = sc.fit_transform(xc_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_test['Driving_Exp'] = sc.fit_transform(xc_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xc_train = pd.DataFrame(xc_train)\n",
    "xc_test = pd.DataFrame(xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7ada48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_C = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                     max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                     min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                     random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_C = AutoInsDT_C.fit(xc_train,yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0bfc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yc_pred = AutoInsDT_C.predict(xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b41daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24814  9150]\n",
      " [ 6235  7579]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76     33964\n",
      "           1       0.45      0.55      0.50     13814\n",
      "\n",
      "    accuracy                           0.68     47778\n",
      "   macro avg       0.63      0.64      0.63     47778\n",
      "weighted avg       0.70      0.68      0.69     47778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09282435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.8 %\n",
      "Precision: 45.3 %\n",
      "Recall: 54.86 %\n",
      "f1-score: 49.63 %\n",
      "roc_auc_score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cef77",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea268cac",
   "metadata": {},
   "source": [
    "# Random Forest with Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c77116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "AutoInsRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    " criterion='gini', max_depth=3, max_features='auto',\n",
    " max_leaf_nodes=None, max_samples=None,\n",
    " min_impurity_decrease=0.0, min_impurity_split=None,\n",
    " min_samples_leaf=1, min_samples_split=2,\n",
    " min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    " n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    " warm_start=False)\n",
    "AutoInsRF = AutoInsRF.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07c03947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "y1_pred = AutoInsRF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "271e4d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34109     0]\n",
      " [ 9769     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34109\n",
      "           1       0.00      0.00      0.00      9769\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y1_pred))\n",
    "print(classification_report(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88041417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.44 %\n",
      "Precision: 63.44 %\n",
      "Recall: 63.44 %\n",
      "f1-score: 63.44 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by mtrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23beb53e",
   "metadata": {},
   "source": [
    "# Random Forest with Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8ebaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_O = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_O = AutoInsRF_O.fit(xo_train, yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d983ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsRF_O.predict(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "470229c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33716   361]\n",
      " [ 2960 31218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     34077\n",
      "           1       0.99      0.91      0.95     34178\n",
      "\n",
      "    accuracy                           0.95     68255\n",
      "   macro avg       0.95      0.95      0.95     68255\n",
      "weighted avg       0.95      0.95      0.95     68255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bef064cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.4 %\n",
      "Precision: 95.4 %\n",
      "Recall: 95.4 %\n",
      "f1-score: 95.4 %\n",
      "roc_auc_score: 0.954\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e5e0e",
   "metadata": {},
   "source": [
    "# Random Forest with Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c1e47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x, y, test_size = 0.30, stratify=y,  random_state =43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eefb6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the random forest model with random sampling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "AutoInsRF_S = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_S = AutoInsRF_S.fit(x2_train,y2_train)\n",
    "AutoInsRF_S = AutoInsRF_S.fit(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "496247e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "y2_pred = AutoInsRF_S.predict(x2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "657bce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34120     7]\n",
      " [ 9748     3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34127\n",
      "           1       0.30      0.00      0.00      9751\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.54      0.50      0.44     43878\n",
      "weighted avg       0.67      0.78      0.68     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y2_test, y2_pred))\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1ca93dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.77 %\n",
      "Precision: 30.0 %\n",
      "Recall: 0.03 %\n",
      "f1-score: 0.06 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y2_test, y2_pred) * 100, 2)), \"%\")\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y2_test, y2_pred) * 100, 2)), '%')\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y2_test, y2_pred) * 100, 2)), \"%\")\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y2_test, y2_pred) * 100, 2)), '%')\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y2_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d08d23",
   "metadata": {},
   "source": [
    "#    Random Forest with Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bbf5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_U = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_U = AutoInsRF_U.fit(xu_train, yu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "907d5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "yu_pred = AutoInsRF_U.predict(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5a0351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3889 5864]\n",
      " [3823 5926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.45      9753\n",
      "           1       0.50      0.61      0.55      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e1d1eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.33 %\n",
      "Precision: 50.33 %\n",
      "Recall: 50.33 %\n",
      "f1-score: 50.33 %\n",
      "roc_auc_score: 0.503\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e792e3",
   "metadata": {},
   "source": [
    "# Random Forest - Combining Over Sampling and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e4010ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164947, 59)\n",
      "(164947,)\n",
      "(164945, 59)\n",
      "(164945,)\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "# Combining Random Oversampling and Undersampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy=0.45)\n",
    "# fit and apply the transform\n",
    "x2, y2 = over.fit_resample(x, y)\n",
    "print(x2.shape)\n",
    "print(y2.shape)\n",
    "# define undersampling strategy\n",
    "under = RandomUnderSampler(sampling_strategy=0.45)\n",
    "# fit and apply the transform\n",
    "x3, y3 = under.fit_resample(x2, y2)\n",
    "print(x3.shape)\n",
    "print(y3.shape)\n",
    "\n",
    "# Combining Random Oversampling and Undersampling \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy=0.50)\n",
    "# fit and apply the transform\n",
    "x2, y2 = over.fit_resample(x, y)\n",
    "print(x2.shape)\n",
    "print(y2.shape)\n",
    "# define undersampling strategy\n",
    "under = RandomUnderSampler(C)\n",
    "# fit and apply the transform\n",
    "x3, y3 = under.fit_resample(x2, y2)\n",
    "print(x3.shape)\n",
    "print(y3.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a906dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113755\n",
       "1     51190\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f39c6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xc_train, xc_test, yc_train, yc_test = train_test_split(x3, y3, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b7fb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transfo\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "xc_train['Driver_Age'] = sc.fit_transform(xc_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_train['Driving_Exp'] = sc.fit_transform(xc_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xc_test['Driver_Age'] = sc.fit_transform(xc_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_test['Driving_Exp'] = sc.fit_transform(xc_test['Driving_Exp'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b8e98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_train = pd.DataFrame(xc_train)\n",
    "xc_test = pd.DataFrame(xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ef3c0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33951    44]\n",
      " [ 7840  7649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90     33995\n",
      "           1       0.99      0.49      0.66     15489\n",
      "\n",
      "    accuracy                           0.84     49484\n",
      "   macro avg       0.90      0.75      0.78     49484\n",
      "weighted avg       0.87      0.84      0.82     49484\n",
      "\n",
      "Accuracy: 84.07 %\n",
      "Precision: 84.07 %\n",
      "Recall: 84.07 %\n",
      "f1-score: 84.07 %\n",
      "roc_auc_score: 0.746\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_C = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_C = AutoInsRF_C.fit(xc_train,yc_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsRF_C.predict(xc_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5475e14",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7805f4d",
   "metadata": {},
   "source": [
    "# Logistic Regression with  Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "469b1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR = AutoInsLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8c0c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "y_pred = AutoInsLR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdcd52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34109     0]\n",
      " [ 9769     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34109\n",
      "           1       0.00      0.00      0.00      9769\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43d22afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.74 %\n",
      "Precision: 77.74 %\n",
      "Recall: 77.74 %\n",
      "f1-score: 77.74 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72ac8e",
   "metadata": {},
   "source": [
    "# Logistic Regression with Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a75f5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To bulid the 'Logistic Regression' model with oversampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_O = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "AutoInsLR_O = AutoInsLR_O.fit(xo_train,yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d3efae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsLR_O.predict(xo_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e95a0a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16548 17529]\n",
      " [16175 18003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50     34077\n",
      "           1       0.51      0.53      0.52     34178\n",
      "\n",
      "    accuracy                           0.51     68255\n",
      "   macro avg       0.51      0.51      0.51     68255\n",
      "weighted avg       0.51      0.51      0.51     68255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d41d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.62 %\n",
      "Precision: 50.62 %\n",
      "Recall: 50.62 %\n",
      "f1-score: 50.62 %\n",
      "roc_auc_score: 0.506\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe5c4b",
   "metadata": {},
   "source": [
    "# Logistic Regression with Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "098c61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x, y, test_size = 0.30, stratify=y,  random_state =43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b033e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the logistic regression model with random sampling\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "AutoInsDT_S =LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsDT_S = AutoInsDT_S.fit(x3_train,y3_train)\n",
    "AutoInsDT_S = AutoInsDT_S.fit(x3_train,y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3f533b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "y3_pred = AutoInsDT_S.predict(x3_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e08ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34127     0]\n",
      " [ 9751     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34127\n",
      "           1       0.00      0.00      0.00      9751\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y3_test, y3_pred))\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0aab27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78 %\n",
      "Precision: 0.0 %\n",
      "Recall: 0.0 %\n",
      "f1-score: 0.0 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y3_test, y3_pred) * 100, 2)), \"%\")\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y3_test, y3_pred) * 100, 2)), '%')\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y3_test, y3_pred) * 100, 2)), \"%\")\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y3_test, y3_pred) * 100, 2)), '%')\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y3_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc0327",
   "metadata": {},
   "source": [
    "# Logistic Regression with Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a22e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_U = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "AutoInsLR_U = AutoInsLR_U.fit(xu_train,yu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53d0f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yu_pred = AutoInsLR_U.predict(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55b6d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4979 4774]\n",
      " [4991 4758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.50      9753\n",
      "           1       0.50      0.49      0.49      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "341c4e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.93 %\n",
      "Precision: 49.93 %\n",
      "Recall: 49.93 %\n",
      "f1-score: 49.93 %\n",
      "roc_auc_score: 0.499\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221b85e",
   "metadata": {},
   "source": [
    "# Logistic Regression - Combining Over Sampling and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89a6b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_C = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR_C = AutoInsLR_C.fit(xc_train,yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d05a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsLR_C.predict(xc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5f4f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34004     0]\n",
      " [24012     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74     34004\n",
      "           1       0.00      0.00      0.00     24012\n",
      "\n",
      "    accuracy                           0.59     58016\n",
      "   macro avg       0.29      0.50      0.37     58016\n",
      "weighted avg       0.34      0.59      0.43     58016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb65d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.61 %\n",
      "Precision: 58.61 %\n",
      "Recall: 58.61 %\n",
      "f1-score: 58.61 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
